---
title: 'ISyE 6404 (EP-2): K-M Estimation, Kernel Regression and Spline'
author:
- Yuan Gao, Kevin Lee, Akshay Govindaraj
- Yijun (Emma) Wan, Peter Williams, Ruixuan Zhang
- ygao390, kylee20, ywan40, agovindaraj6, pwilliams60, rzhang438 | @gatech.edu
date: '2018-10-22'
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  word_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(reshape2))
suppressPackageStartupMessages(library(survival))
```

## 1. K-M Estimation (25%):
*Locate a data set with right-censoring (in Type-I Censoring) in the field of your interest, e.g., eCommerce, medical study, drug development, supply-chain/logistics operations, for applying the K-M Estimator to estimate the survival function with pointwise confidence intervals.*  

For this exercise, we located a dataset, that consists of measures on 69 different patients who received a heart transplant, taken from the first edition of the text *The Statistical Analysis of Failure Time Data* by Kalbfleisch and Prentice, Appendix I (230-232), published originally in 1980, which can also be found via the following link on the Carnegie Mellon statistics site: http://lib.stat.cmu.edu/datasets/stanford, and has three columns with the following measures:  

* Age: Age of patient in years at the time of heart transplant in years
* Status: Survival status (1=dead, 0=alive)
* Days: Survival time in days after transplant (in days)   

```{r ht_prv, echo = F, include = T}
hdat <- read.csv('data/heart_transplant.csv',header=T,stringsAsFactors=F)
knitr::kable(hdat[c(1,2,8,12,16,32),],  caption="Preview: Heart Transplant Data",row.names=F)
```

This dataset is right censored, because as shown above, we don't exactly how long patients who currently have a (status=0) will survive, or survived.  

Utilizing this dataset, and the *survival* package in R, we generate the Kaplan-Meier estimates, and visualize the survival function, i.e. $S_{KM}(x_{i:n}) = 1 - F_{KM}(x_{i:n})$, with confidence intervals below. Note that the R code utilized is also shown:  

\newpage

##### R Code  
  
```{r km_estimate, echo = T, include = T, fig.align='center',fig.height=4}
km_fit <- survfit(Surv(time = Days, event = Status) ~ 1, data = hdat, 
                  type = 'kaplan-meier') #only one group of patients
km_dat <- data.frame(time=km_fit$time,
                     survival=km_fit$surv,
                     upper_ci = km_fit$upper, 
                     lower_ci = km_fit$lower) #model results
melted_km_dat <- melt(km_dat, id.vars = c('time')) #transform for viz
ggplot(aes(x=time,y=value, color = variable ,group = variable), data=melted_km_dat) +
  geom_step(size = 1.25) + theme_bw() + xlab('Time (days)') + 
  ylab('Survival Function') + 
  ggtitle('K-M Estimates with 95% Confidence Bounds: Heart Transplant Patients') + 
  labs(color='Curve')
```
  

Visual analysis of the plot here, indicates that the probability of survival for 500 days, after a heart transplant is approximately 42%, with a 95% confidence range of approximately 30-55%, among patients in this data, when this data was collected decades ago. We hope that survival rates have increased significantly since this study was conducted. 

## 2. Kernel and Related Regression with One Explanatory Variable (40%):
*Locate a data set suitable for nonparametric regression (usually has nonlinear y-x relationship) in the field of your interest, e.g., eCommerce, medical study, drug development, supply-chain/logistics operations. Apply all of the procedures below:*  

1) *Kernel Regression,*    
2) *Local Polynomial Regression,*    
3) *LOESS,*    
4) *Smoothing Spline, to the y-x data-fit.*     
    + Compare fits from the four methods.   
For this exercise, we located another dataset, that consists of Data give the mortality rate and the education level for 58 U.S. cities. It can be found via the following link on the *The Data And Story Library* site:https://dasl.datadescription.com/datafile/education-and-mortality, and has two columns with the following measures:  

* Mortality: the mortality rate (deaths per 100,000 people)
* Education: the average number of years in school
```{r km_estimate, echo = T, include = T, fig.align='center',fig.height=4}
rdat <- read.csv('data/education-and-mortality.csv',header=T,stringsAsFactors=F)
bw <- npregbw(formula=rdat$Mortality~rdat$Education, tol=.1, ftol=.1)
# Now take these bandwidths and fit the model and gradients
model <- npreg(bws = bw, gradients = TRUE)
summary(model)
npplot(bws=bw, plot.errors.method="bootstrap")
points(rdat$Education, rdat$Mortality, cex=.2, col="red")

plot(NA, xlim = c(min(rdat$Education), max(rdat$Education)), ylim = c(0, 1))
lines(locpoly(rdat$Education, rdat$Mortality, bandwidth=2, degree=1), col=3)
```

## 3. Cross-Validation With the “Leave-One-Out” Procedure (10%):
*Compare the above four methods with a leave-one-out cross-validation procedure.*  

## 4. Resampling Procedures: Bootstrap and Jackknife (25%):
1) *Select an input $x_0$ in the [min(x-data), max(x-data)].*  
2) *Use all four regression models built in Task #2 to make point-predictions of $Y$ at $x_0$.*  
3) *Use both bootstrap ($B = 1000$) and jackknife resampling procedures to find a 90% pointwise confidence interval (CI) for the point-prediction. If the resampled distribution of the point-prediction is symmetric, use 5% in each tail to find the CI-bounds. If the distribution is not symmetric, use the HPD-interval idea to find the CI-bound. Compare the results from four regression methods.*  


